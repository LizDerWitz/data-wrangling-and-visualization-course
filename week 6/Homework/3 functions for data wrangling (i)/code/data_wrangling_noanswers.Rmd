---
title: "Practicing data wrangling"
author: "Template: Ian Hussey; content: [Student name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Dependencies

```{r}

library(dplyr)
library(tidyr)
library(readr)
library(janitor) # for clean_names()
library(stringr)
library(knitr)
library(kableExtra)

```

# How to access help menu 

For any function in a loaded package, simply type `?` before the function's name to call up the help menu. This helps you understand the function's purpose, its arguments, and outputs.

```{r}

?read_csv

```

- Why use {reader}'s `read_csv()` over the base R `read.csv()`? Because `read_csv()` is more explicit about what assumption it is making about column types, and prints warning messages about what it has assumed.

# Relative vs. absolute paths & loading data

This data comes from a real study on implicit and self-reported evaluations. The implementation of the procedure produced three data files: one for the demographics data, one for the self-reported evaluations, and one for the implicit measure (the 'Affect Misattribution Procedure'). This script uses each of these to learn and practice functions from the readr, dplyr, and tidyr libraries that are commonly used for data wrangling. In doing so, we will learn how to do many of the steps involved in data processing for a given experiment. 

## Never use `setwd()`

\TODO add explainer - breaks between machines, breaks between mac and windows


## Use relative paths

Either through Rmarkdown files, Quarto files, or in regular .R files using the {here} library (see https://here.r-lib.org/).

```{r}

# demographics data
data_demographics_raw <- read_csv(file = "../data/raw/data_demographics_raw.csv") 

# self report measure data
data_selfreport_raw <- read_csv(file = "../data/raw/data_selfreport_raw.csv") 

# affect attribution procedure data
data_amp_raw <- read_csv(file = "../data/raw/data_amp_raw.csv")

```

# Count number of rows

A very early step in any data processing is to understand how many rows are in a data frame, as this often represents the number of participants or total number of trials. This is useful to check at multiple steps of your data processing to make sure you have not done something wrong. 

```{r}



```

- Why are there different number of rows in the three data frames when this data all comes from the same participants? 

- Why are the numbers not round?



# The pipe (%>% or %>%) 

`%>%` is the original pipe created for the {magrittr} package and used throughout the tidyverse packages. It is slightly slower but also more flexible.

`%>%` is a version of the pipe more recently added to base-R. It is slightly faster but less flexible. 

If you're not sure, it's easier to use `%>%`. 

## What is the pipe?

The output of what is left of the pipe is used as the input to the right of the pipe, usually as the first argument or the data argument.

```{r}



```

## Why use the pipe?

The pipe allows us to write code that reads from top to bottom, following a series of steps, in the way that humans organize and describe steps. Without the pipe, code is written from the inside out, in the way that the computer understands it but humans do not as easily.

```{r}



```

The utility of this becomes more obvious when there are many steps:

```{r}



```

# Using the pipe & cleaning column names

It is almost always useful to start by converting all column names to ones that play nice with R/tidyverse and which use the same naming convention (e.g., snake_case, which is standard in tidyverse).

How would you bring up the help menu to understand how `janitor::clean_names()` works?

Rewrite each of the below to use the pipe.

```{r}


```

# Viewing column names

How would you know what variables are in a data frame? You can view the data frame, but it can also be useful to print them. Knowing what you have is one of the first steps to working with it.

```{r}

```

# Renaming columns 

Often variable names are not intuitive. An early step in any data wrangling is to make them more intuitive.

```{r}


```

# Selecting columns 

Not all variables are useful to you. An early step in any data wrangling is to drop the columns that you don't need.

```{r}



```

# Practice the pipe again

Combine the above function calls using pipes. Notice how this involves fewer objects in your environment, and therefore less potential for confusion or error.

Remember: this is how we solve coding problems: break them down into smaller tasks and problems, get each of them working individually, then combine them together again. When you only see the end product, it's easy to think the author simply wrote the code as you see it, when they often wrote much more verbose chunks of code and then combined them together.

```{r}


```

# Counting frequencies 

After renaming and selecting columns, we know what columns we have. But what rows do we have in each of these? What might we need to exclude, change, work with in some way later on? It is very useful to use `count()` to obtain the frequency of each unique value of a given column

```{r}


```

```{r}



```

```{r}

```

## Frequncies of sets of columns

Note that it is also possible to use count to obtain the frequencies of sets of unique values across columns, e.g., unique combinations of item and response.

```{r}



```

It can be useful to arrange the output by the frequencies.

```{r}


```

# Filtering rows 

Once we know the contents of our columns, we may wish to exclude some rows using `filter()`.

You can specify the logical test for filtering in many ways, including equivalence (`==`), negation (`!=`), or membership (`%in%`). It is often better to define what you *do* want (using equivalence or membership) rather than what you *do not* want (negation), as negations are less robust to new data with weird values you didn't think of when you wrote the code. E.g., you could specify `gender != "non-binary"` but this would not catch `non binary`. If you were for example looking to include only men and women, instead use `gender %in% c("man", "woman")`.* 

*[This is just an example; there is usually no good a priori reason to exclude gender diverse participants]

```{r}


```

## Multiple criteria, 'and' or 'or' combinations

You can also have multiple criteria in your filter call, both of which have to be met (x `&` y), or either one of which have to be met (x `|` y).

```{r}


```

## Practice filtering

Filter the self reports data frame to remove the instructions. Filter the AMP data frame to remove the practice blocks and the instruction trials.

```{r}


```

# Check your learning

What is the difference between select and filter?

Which is for rows and which is for columns?

# Mutating: creating new columns or changing the contents of existing ones

## Understanding `mutate()`

`mutate()` is used to create new columns or to change the contents of existing ones.

```{r}



```

The operations inside mutate can range from the very simple, like the above, to much more complex. The below example uses other functions we haven't learned yet. For now, just notice that there can be multiple mutate calls and they can produce a cleaned up gender variable.

```{r}

```
A single mutate call can contain multiple mutates. The code from the last chunk could be written more simply like this:

```{r}



```

## Practice `mutate()`

When analyzing cognitive behavioral tasks, it is common to employ mastery criteria to exclude participants who have not met or maintained some criterion within the task. We'll do the actual exclusions etc. later on, but for practice using `mutate()` by creating a new `fast_trial` column to indicate trials where the response was implausibly fast (e.g., < 100 ms).

Try doing this with a simple logical test of whether latency < 100. You can do this with or without using the `ifelse()` function.

```{r}



```

## Practice `mutate()` & learn `ifelse()`

Use `mutate()` to remove weird values from `data_demographics_trimmed$response`, for the rows referring to age, that aren't numbers.

What function could you use to first determine what values are present in this column, to know which could be retained or changed?

In simple cases like this, you can use `mutate()` and `ifelse()` to change impossible values to `NA`. 

```{r}



```

## Practice `mutate()` & `ifelse()`

Use `mutate()` to remove weird values from `data_selfreport_trials$response` that aren't Likert responses.

First determine what values are present in this column.

Use `ifelse()` and `%in%` inside `mutate()` to change values other than the Likert responses to `NA`.

**If you struggle to do this: practice writing 'pseudocode' here. That is, without knowing the right code, explain in precise logic what you want the computer to do. This can be converted to R more easily.** 

```{r}




```

What other ways are there of implementing this mutate, e.g., without using `%in%`? What are the pros and cons of each?

```{r}

# write examples here

```

## Practice `mutate()` & learn `case_when()`

`case_when()` allows you to compare multiple logical tests or if-else tests.

The AMP data needs to be reverse scored. Just like an item on a self-report that is worded negatively (e.g., most items: I am a good person; some items: I am a bad person), the negative prime trials have the opposite 'accuracy' values that they should. Use `mutate()` and `case_when()` to reverse score the negative prime trials, so that what was 0 is now 1 and what was 1 is now 0.

```{r}


  
```

# Mini-lesson: `round()` probably doesn't do what you think

Did you know that R doesn't use the rounding method most of us are taught in school, where .5 is rounded up to the next integer? Instead it uses "banker's rounding", which is better when you round a very large number of numbers, but worse for reporting the results of specific analyses. 

This is easier to show than explain. What do you expect the output of the below chunk to be? And what is the actual output?

```{r}


```

Remember: you probably need to use `janitor::round_half_up()` in most of your R scripts

```{r}



```

# Summarizing across rows

It is very common that we need to create summaries across rows. For example, to create the mean and standard deviation of a column like age. This can be done with `summarize()`. Remember: `mutate()` creates new columns or modifies the contents of existing columns, but does not change the number of rows. Whereas `summarize()` reduces a data frame down to one row.

```{r}

```

## `group_by()`

Often, we don't want to reduce a data frame down to a single row / summarize the whole dataset, but instead we want to create a summary for each (sub)group. For example

```{r}


```

## `n()`

`n()` calculates the number of rows, i.e., the N. It can be useful in summarize.

```{r}



```

Note that `count()` is just the combination of group_by() and summiarize() and n()! they produce the same results as above.

```{r}


```

## More complex summarizations

Like mutate, the operation you do to summarize can also be more complex, such as finding the mean result of a logical test to calculate a proportion. For example, the proportion of participants who are less than 25 years old: 

```{r}



```

You can also summarize (or indeed mutate) multiple columns in the same way using `across()`, for do-this-across-columns. We won't cover how to use this here or all the variations that are possible, just know that it can be done. For example:

```{r}



```

## Practice using `summarize()`

Calculate the min, max, mean, and SD of all responses on the self report data.

Currently each participant has up to three responses on the self-report scales (three item scale: like, positive, and prefer). Create a new dataframe containing each unique_id's mean score across the items. Also calculate how many items each participant has data for, and whether they have complete data (i.e., data for three items).

Using only participants with complete data, calculate the mean and SD of all participant's mean scores on the self-reports.

```{r}

# data_selfreport_tidy

```

Create a new data frame that calculates the proportion of prime-congruent trials for each participant on the AMP (i.e., the mean of the 'correct' column) and their proportion of too-fast trials.

Add to that data frame a new column called "exclude_amp" and set it to "exclude" if more than 10% of a participant's trials are too-fast trials.

Calculate the proportion of participants who are to be excluded.

```{r}

# data_amp_tidy

```

# Check your learning

What is the difference between `mutate()` and `summarize()`? If I use the wrong one, will I get the same answer? E.g., mutate(mean_age = mean(age, na.rm = TRUE)) vs. summarize(mean_age = mean(age, na.rm = TRUE))

# Joining data frames

\TODO add 

# Nicer tables using kable() and kable_classic()

Nicer tables can be printed using many different packages. I tend to use the combination of `knitr::kable()` and `kableExtra::kable_classic()`. Whenever I print a plot below a chunk, I use these. I have not used them in this R Markdown file until now just to keep the code simpler.

```{r}



```

# Writing data to disk

\TODO add 

# Comment and Knit early, comment and knit often

\TODO add note

# Session info

You can help make your code and results more reproducible by including a `sessionInfo()` call at the end of your scripts. This prints details of your operating system, R version, and packages that were used in your script. When you click knit to create a 

```{r}

sessionInfo()

```


